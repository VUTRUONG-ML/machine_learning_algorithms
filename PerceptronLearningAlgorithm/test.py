import numpy as np 
import pandas as pd
import re
import string
import nltk
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import Perceptron
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import StandardScaler
def predict(w, X):
    return np.sign(X @ w) # X shape (n_samples, n_features), w shape (n_features,)

def perceptronAl(w_init, X, y):
    w = [w_init]
    i = 0 
    while True:
        i += 1 
        y_pred = predict(w[-1], X)
        lstMiss = np.where(np.equal(y_pred, y) == False)[0]
        if len(lstMiss) == 0 or i == 5000:
            break 
        random_id = np.random.choice(lstMiss, 1)[0]
        w_new = w[-1] + X[random_id]*y[random_id]
        w.append(w_new)
    return w[-1]


# Táº£i danh sÃ¡ch stopwords (náº¿u chÆ°a cÃ³, cháº¡y `nltk.download('stopwords')`)
vietnamese_stopwords = {"báº¡n", "Ä‘Ã£", "vÃ ", "nháº­n", "ngay", "cÃ³", "lÃ ", "cá»§a", "tÃ´i"}

def clean_text(text):
    text = text.lower()
    text = re.sub(f"[{string.punctuation}]", "", text)
    words = text.split()
    words = [word for word in words if word not in vietnamese_stopwords]
    return " ".join(words)

data = [
    ("Báº¡n Ä‘Ã£ trÃºng thÆ°á»Ÿng 10 triá»‡u Ä‘á»“ng! Nháº¥p vÃ o link Ä‘á»ƒ nháº­n.", "Spam"),
    ("Anh Æ¡i, tá»‘i nay mÃ¬nh Ä‘i Äƒn khÃ´ng?", "Ham"),
    ("KhÃ¡ch hÃ ng thÃ¢n máº¿n, quÃ½ vá»‹ Ä‘Æ°á»£c giáº£m giÃ¡ 50% cho Ä‘Æ¡n hÃ ng tiáº¿p theo!", "Spam"),
    ("Nhá»› lÃ m bÃ i táº­p nhÃ©, mai cÃ³ kiá»ƒm tra Ä‘áº¥y!", "Ham"),
    ("Nháº­n ngay 500.000 VND khi Ä‘Äƒng kÃ½ tÃ i khoáº£n táº¡i Ä‘Ã¢y: www.lá»«aÄ‘áº£o.com", "Spam"),
    ("Em Ä‘Ã£ gá»­i email, anh check giÃºp em nhÃ©.", "Ham"),
    ("Bá»‘ máº¹ khá»e khÃ´ng con? Bao giá» con vá» thÄƒm nhÃ ?", "Ham"),
    ("ğŸ’° Vay ngay 100 triá»‡u khÃ´ng cáº§n tháº¿ cháº¥p, lÃ£i suáº¥t 0% thÃ¡ng Ä‘áº§u tiÃªn! ğŸ’°", "Spam"),
    ("Báº¡n cÃ³ Ä‘Æ¡n hÃ ng chÆ°a thanh toÃ¡n, hÃ£y thanh toÃ¡n sá»›m Ä‘á»ƒ trÃ¡nh bá»‹ há»§y.", "Ham"),
    ("TÃ i khoáº£n cá»§a báº¡n cÃ³ dáº¥u hiá»‡u Ä‘Äƒng nháº­p láº¡, vui lÃ²ng xÃ¡c minh ngay!", "Spam"),
    ("Gá»i ngay Ä‘á»ƒ nháº­n Æ°u Ä‘Ã£i khá»§ng tá»« nhÃ  máº¡ng cá»§a báº¡n!", "Spam"),
    ("Nhá»› uá»‘ng Ä‘á»§ nÆ°á»›c má»—i ngÃ y Ä‘á»ƒ cÆ¡ thá»ƒ khá»e máº¡nh nhÃ©!", "Ham"),
    ("CÃ´ng ty chÃºng tÃ´i Ä‘ang tuyá»ƒn dá»¥ng, lÆ°Æ¡ng cao, khÃ´ng yÃªu cáº§u kinh nghiá»‡m!", "Spam"),
    ("Cáº£m Æ¡n báº¡n Ä‘Ã£ mua hÃ ng táº¡i cá»­a hÃ ng cá»§a chÃºng tÃ´i!", "Ham"),
    ("Lá»‹ch thi Ä‘áº¥u bÃ³ng Ä‘Ã¡ hÃ´m nay: 20h00 - Viá»‡t Nam vs ThÃ¡i Lan", "Ham"),
    ("Náº¡p tháº» Ä‘iá»‡n thoáº¡i ngay Ä‘á»ƒ nháº­n thÃªm 50% giÃ¡ trá»‹ khuyáº¿n mÃ£i!", "Spam"),
    ("Há»c láº­p trÃ¬nh Python khÃ´ng? MÃ¬nh cÃ³ khÃ³a há»c miá»…n phÃ­ Ä‘Ã¢y!", "Spam"),
    ("Báº¡n cÃ³ háº¹n gáº·p bÃ¡c sÄ© vÃ o ngÃ y mai, Ä‘á»«ng quÃªn nhÃ©!", "Ham"),
    ("Truy cáº­p ngay website cá»§a chÃºng tÃ´i Ä‘á»ƒ nháº­n pháº§n thÆ°á»Ÿng báº¥t ngá»!", "Spam"),
    ("Máº¹ Ä‘ang náº¥u mÃ³n con thÃ­ch nháº¥t, vá» nhÃ  ngay nhÃ©!", "Ham"),
    ("Táº£i ngay á»©ng dá»¥ng má»›i Ä‘á»ƒ nháº­n 100.000 VND miá»…n phÃ­!", "Spam"),
    ("Háº¹n gáº·p láº¡i báº¡n vÃ o tuáº§n sau nhÃ©!", "Ham"),
    ("Nháº­p mÃ£ khuyáº¿n mÃ£i XYZ Ä‘á»ƒ giáº£m ngay 20%!", "Spam"),
    ("Anh cÃ³ thá»ƒ gá»­i láº¡i file bÃ¡o cÃ¡o khÃ´ng?", "Ham"),
    ("ÄÄƒng kÃ½ ngay hÃ´m nay Ä‘á»ƒ nháº­n quÃ  táº·ng háº¥p dáº«n!", "Spam"),
    ("SÃ¡ng mai em cÃ³ lá»‹ch há»p, anh nhá»› Ä‘áº¿n nhÃ©!", "Ham"),
    ("ChÃºc má»«ng báº¡n Ä‘Ã£ nháº­n Ä‘Æ°á»£c mÃ£ giáº£m giÃ¡ 30%", "Spam"),
    ("Tá»‘i nay ráº£nh khÃ´ng? Äi xem phim nhÃ©!", "Ham"),
    ("Cáº£nh bÃ¡o! TÃ i khoáº£n cá»§a báº¡n cÃ³ hoáº¡t Ä‘á»™ng Ä‘Ã¡ng ngá»!", "Spam"),
    ("Báº¡n Æ¡i, cÃ³ thá»ƒ giÃºp mÃ¬nh bÃ i táº­p nÃ y khÃ´ng?", "Ham"),
    ("Má»Ÿ tÃ i khoáº£n ngay Ä‘á»ƒ nháº­n lÃ£i suáº¥t háº¥p dáº«n!", "Spam"),
    ("HÃ´m nay trá»i Ä‘áº¹p quÃ¡, Ä‘i dáº¡o khÃ´ng?", "Ham"),
    ("Mua 1 táº·ng 1 trong hÃ´m nay! Nhanh tay lÃªn!", "Spam"),
    ("Sáº¿p yÃªu cáº§u gá»­i bÃ¡o cÃ¡o gáº¥p!", "Ham"),
    ("Nháº­n ngay Æ°u Ä‘Ã£i Ä‘áº·c biá»‡t khi Ä‘áº·t hÃ ng online!", "Spam"),
    ("ChÃºc má»«ng sinh nháº­t! ChÃºc báº¡n má»™t ngÃ y vui váº»!", "Ham"),
    ("Cáº£nh bÃ¡o: MÃ¡y tÃ­nh cá»§a báº¡n cÃ³ nguy cÆ¡ nhiá»…m virus!", "Spam"),
    ("Anh Ä‘Ã£ Ä‘áº·t bÃ n chÆ°a? Nhá»› bÃ¡o em nhÃ©!", "Ham"),
    ("Nháº¥n vÃ o Ä‘Ã¢y Ä‘á»ƒ nháº­n quÃ  may máº¯n!", "Spam"),
    ("Mai cÃ³ buá»•i há»p quan trá»ng, Ä‘á»«ng quÃªn nhÃ©!", "Ham"),
    ("Táº£i á»©ng dá»¥ng ngay Ä‘á»ƒ nháº­n 10GB data miá»…n phÃ­!", "Spam"),
    ("MÃ¬nh Ä‘áº¿n nÆ¡i rá»“i, báº¡n Ä‘ang á»Ÿ Ä‘Ã¢u?", "Ham"),
    ("Sá»‘ dÆ° tÃ i khoáº£n ngÃ¢n hÃ ng cá»§a báº¡n Ä‘Ã£ thay Ä‘á»•i!", "Spam"),
    ("HÃ´m nay cÃ³ lá»‹ch háº¹n vá»›i bÃ¡c sÄ© lÃºc 14h", "Ham"),
    ("Nháº­n ngay mÃ£ giáº£m giÃ¡ khi mua sáº¯m táº¡i cá»­a hÃ ng!", "Spam"),
    ("Lá»‹ch há»c tuáº§n nÃ y cÃ³ thay Ä‘á»•i, nhá»› kiá»ƒm tra nhÃ©!", "Ham"),
    ("Báº¡n Ä‘Ã£ trÃºng giáº£i Ä‘áº·c biá»‡t, liÃªn há»‡ ngay Ä‘á»ƒ nháº­n thÆ°á»Ÿng!", "Spam"),
    ("Máº¹ nhá»› con láº¯m, bao giá» con vá»?", "Ham")
]

# Táº¡o DataFrame
df = pd.DataFrame(data, columns=["Message", "Label"])

df["Message"] = df["Message"].apply(clean_text)

# Chuyá»ƒn vÄƒn báº£n thÃ nh vector TF-IDF
vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(df["Message"])
# Chuyá»ƒn nhÃ£n thÃ nh sá»‘ (Spam = 1, Ham = 0)
y = df["Label"].map({"Spam": 1, "Ham": 0})

# Chia dá»¯ liá»‡u thÃ nh táº­p train vÃ  test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

X_train, X_test = X_train.toarray(), X_test.toarray()
y_train = y_train.to_numpy()  # Chuyá»ƒn Series -> numpy array
y_test = y_test.to_numpy()



w_init = np.zeros(X_train.shape[1])
# Train mÃ´ hÃ¬nh
w_final = perceptronAl(w_init, X_train, y_train)

# Kiá»ƒm tra trÃªn táº­p test
y_pred = predict(w_final, X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"Äá»™ chÃ­nh xÃ¡c cá»§a mÃ´ hÃ¬nh: {accuracy * 100:.2f}%")